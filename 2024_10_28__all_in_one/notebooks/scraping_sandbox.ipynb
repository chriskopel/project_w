{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The goal here is to input any team, search through a list, and return that team rather than having disparate classes for each one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soccer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fb_data = pd.read_csv(r\"C:\\Users\\Owner\\Documents\\Data Projects\\GitHub\\Apps\\project_w\\data\\football_data.csv\")\n",
    "fb_data = pd.read_csv(\"/Users/ckopel/Github/project_w/data/football_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "team = 'Aston Villa'\n",
    "team_url = fb_data[fb_data['team'] == team].url.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the ChromeDriver path from your environment variable\n",
    "chrome_driver_path = os.getenv('chrome_driver_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "\n",
    "    # Setup WebDriver\n",
    "    service = Service(chrome_driver_path)  # Use the path from environment variable\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "\n",
    "    # Open the page\n",
    "    driver.get(team_url)\n",
    "    \n",
    "    # Wait until the cookie popup is present and clickable\n",
    "    WebDriverWait(driver, 5).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//button[text()='Reject All']\"))\n",
    "    ).click()\n",
    "\n",
    "    # Now proceed with your scraping task\n",
    "    ## Use BeautifulSoup to parse the page source once the page is fully loaded\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    # Find the table and extract data as before\n",
    "    table = soup.find_all('table', class_='matches')\n",
    "    dates = [row.text for row in table[0].find_all('td', class_=\"full-date\")]\n",
    "    leagues = [row.text.strip() for row in table[0].find_all('td', class_=\"competition\")]\n",
    "    homes = [row.text.strip() for row in table[0].find_all('td', class_=\"team\")[::2]]\n",
    "    aways = [row.text.strip() for row in table[0].find_all('td', class_=\"team\")[1::2]]\n",
    "    times = [row.text.strip() for row in table[0].find_all('td', class_=\"score-time\")]\n",
    "\n",
    "    # Create dataframes\n",
    "    df_fixtures = pd.DataFrame(\n",
    "        {\n",
    "            'Date': dates,\n",
    "            'League': leagues,\n",
    "            'Home team': homes,\n",
    "            'Time': times,\n",
    "            'Away team': aways\n",
    "        }\n",
    "    )\n",
    "\n",
    "except TimeoutException:\n",
    "    print(\"Timed out waiting for cookie pop-up or other elements\")\n",
    "finally:\n",
    "    # Close the browser\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try the matches tab scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_url_m = team_url + 'matches/'\n",
    "team_url_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the ChromeDriver path from your environment variable\n",
    "chrome_driver_path = os.getenv('chrome_driver_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "\n",
    "    # Setup WebDriver\n",
    "    service = Service(chrome_driver_path)  # Use the path from environment variable\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "\n",
    "    # Open the page\n",
    "    driver.get(team_url_m)\n",
    "    \n",
    "    # Wait until the cookie popup is present and clickable\n",
    "    WebDriverWait(driver, 5).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//button[text()='Reject All']\"))\n",
    "    ).click()\n",
    "\n",
    "    # Now proceed with your scraping task\n",
    "    ## Use BeautifulSoup to parse the page source once the page is fully loaded\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    # Find the table and extract data as before\n",
    "    table = soup.find_all('table', class_='matches')\n",
    "    dates = [row.text for row in table[0].find_all('td', class_=\"full-date\")]\n",
    "    leagues = [row.text.strip() for row in table[0].find_all('td', class_=\"competition\")]\n",
    "    homes = [row.text.strip() for row in table[0].find_all('td', class_=\"team\")[::2]]\n",
    "    aways = [row.text.strip() for row in table[0].find_all('td', class_=\"team\")[1::2]]\n",
    "    times = [row.text.strip() for row in table[0].find_all('td', class_=\"score-time\")]\n",
    "\n",
    "    # Create dataframes\n",
    "    df_fixtures = pd.DataFrame(\n",
    "        {\n",
    "            'Date': dates,\n",
    "            'League': leagues,\n",
    "            'Home team': homes,\n",
    "            'Time': times,\n",
    "            'Away team': aways\n",
    "        }\n",
    "    )\n",
    "\n",
    "except TimeoutException:\n",
    "    print(\"Timed out waiting for cookie pop-up or other elements\")\n",
    "finally:\n",
    "    # Close the browser\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fixtures.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through each soccer team for df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dictionary\n",
    "team_url_dict = fb_data.set_index('team')['url'].to_dict()\n",
    "\n",
    "# Amend each URL by adding 'matches/' at the end\n",
    "team_url_dict = {team: url + 'matches/' for team, url in team_url_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the first three key-value pairs\n",
    "# first_three = {k: team_url_dict[k] for k in list(team_url_dict.keys())[:3]}\n",
    "# first_three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the ChromeDriver path from your environment variable\n",
    "chrome_driver_path = os.getenv('chrome_driver_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for team, url in team_url_dict.items():\n",
    "\n",
    "    try:\n",
    "\n",
    "        # Setup WebDriver\n",
    "        service = Service(chrome_driver_path)  # Use the path from environment variable\n",
    "        driver = webdriver.Chrome(service=service)\n",
    "\n",
    "        # Open the page\n",
    "        driver.get(url)\n",
    "        \n",
    "        # Wait until the cookie popup is present and clickable\n",
    "        WebDriverWait(driver, 5).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//button[text()='Reject All']\"))\n",
    "        ).click()\n",
    "\n",
    "        # Now proceed with your scraping task\n",
    "        ## Use BeautifulSoup to parse the page source once the page is fully loaded\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        # Find the table and extract data as before\n",
    "        table = soup.find_all('table', class_='matches')\n",
    "        dates = [row.text for row in table[0].find_all('td', class_=\"full-date\")]\n",
    "        leagues = [row.text.strip() for row in table[0].find_all('td', class_=\"competition\")]\n",
    "        homes = [row.text.strip() for row in table[0].find_all('td', class_=\"team\")[::2]]\n",
    "        aways = [row.text.strip() for row in table[0].find_all('td', class_=\"team\")[1::2]]\n",
    "        times = [row.text.strip() for row in table[0].find_all('td', class_=\"score-time\")]\n",
    "\n",
    "        # Create dataframes\n",
    "        df_team_fixtures = pd.DataFrame(\n",
    "            {\n",
    "                'Team': team,\n",
    "                'Date': dates,\n",
    "                'League': leagues,\n",
    "                'Home Team': homes,\n",
    "                'Time': times,\n",
    "                'Away Team': aways\n",
    "            }\n",
    "        )\n",
    "\n",
    "        ## Add to master df\n",
    "        if 'df_fb_master' in locals():\n",
    "            df_fb_master = pd.concat([df_fb_master, df_team_fixtures], ignore_index=True)\n",
    "        else:\n",
    "            df_fb_master = df_team_fixtures.copy()\n",
    "\n",
    "\n",
    "    except TimeoutException:\n",
    "        print(f\"Timed out waiting for cookie pop-up or other elements for {team} at {url}\")\n",
    "        \n",
    "    finally:\n",
    "        # Close the browser\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manchester City https://ng.soccerway.com//teams/england/manchester-city-football-club/676/matches/\n"
     ]
    }
   ],
   "source": [
    "print(team,url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fb_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fb_master.Team.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fb_master.groupby('Team').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fb_master.to_csv('df_fb_master_2024_10_28.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Troubleshoot the fb selenium scrape (2024-11-11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dictionary\n",
    "team_url_dict = fb_data.set_index('team')['url'].to_dict()\n",
    "\n",
    "# Amend each URL by adding 'matches/' at the end\n",
    "team_url_dict = {team: url + 'matches/' for team, url in team_url_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Arsenal': 'https://ng.soccerway.com//teams/england/arsenal-fc/660/matches/',\n",
       " 'Manchester City': 'https://ng.soccerway.com//teams/england/manchester-city-football-club/676/matches/',\n",
       " 'Newcastle United': 'https://ng.soccerway.com//teams/england/newcastle-united-football-club/664/matches/'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the first three key-value pairs\n",
    "first_three = {k: team_url_dict[k] for k in list(team_url_dict.keys())[:3]}\n",
    "first_three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arsenal https://ng.soccerway.com//teams/england/arsenal-fc/660/matches/\n"
     ]
    }
   ],
   "source": [
    "# Get the first key\n",
    "first_key = next(iter(team_url_dict))\n",
    "\n",
    "# Get the first value\n",
    "first_value = team_url_dict[first_key]\n",
    "\n",
    "print(first_key, first_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manchester City https://ng.soccerway.com//teams/england/manchester-city-football-club/676/matches/\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "# Use islice to get the second item\n",
    "second_item = next(islice(team_url_dict.items(), 1, 2))  # start at 1 (second item), stop at 2 (exclusive)\n",
    "\n",
    "second_key, second_value = second_item\n",
    "\n",
    "print(second_key, second_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the ChromeDriver path from your environment variable\n",
    "chrome_driver_path = os.getenv('chrome_driver_path')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fb_selenium_scrape(team, fb_url):\n",
    "    try:\n",
    "\n",
    "        # Setup WebDriver\n",
    "        service = Service(chrome_driver_path)  # Use the path from environment variable\n",
    "        driver = webdriver.Chrome(service=service)\n",
    "\n",
    "        # Open the page\n",
    "        driver.get(fb_url)\n",
    "        \n",
    "        # Wait until the cookie popup is present and clickable\n",
    "        WebDriverWait(driver, 5).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//button[text()='Reject All']\"))\n",
    "        ).click()\n",
    "\n",
    "        # Now proceed with your scraping task\n",
    "        ## Use BeautifulSoup to parse the page source once the page is fully loaded\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        # Find the table and extract data as before\n",
    "        table = soup.find_all('table', class_='matches')\n",
    "        dates = [row.text for row in table[0].find_all('td', class_=\"full-date\")]\n",
    "        leagues = [row.text.strip() for row in table[0].find_all('td', class_=\"competition\")]\n",
    "        homes = [row.text.strip() for row in table[0].find_all('td', class_=\"team\")[::2]]\n",
    "        aways = [row.text.strip() for row in table[0].find_all('td', class_=\"team\")[1::2]]\n",
    "        times = [row.text.strip() for row in table[0].find_all('td', class_=\"score-time\")]\n",
    "\n",
    "        # Create dataframes\n",
    "        df_team_fixtures = pd.DataFrame(\n",
    "            {\n",
    "                'Team': team,\n",
    "                'Date': dates,\n",
    "                'League': leagues,\n",
    "                'Home Team': homes,\n",
    "                'Time': times,\n",
    "                'Away Team': aways\n",
    "            }\n",
    "        )\n",
    "\n",
    "        return df_team_fixtures\n",
    "\n",
    "\n",
    "    except TimeoutException:\n",
    "        print(f\"Timed out waiting for cookie pop-up or other elements for {team} at {url}\")\n",
    "        \n",
    "    finally:\n",
    "        # Close the browser\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_team_fixtures = fb_selenium_scrape(team = second_key, fb_url = second_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arsenal https://ng.soccerway.com//teams/england/arsenal-fc/660/matches/\n",
      "Manchester City https://ng.soccerway.com//teams/england/manchester-city-football-club/676/matches/\n",
      "Newcastle United https://ng.soccerway.com//teams/england/newcastle-united-football-club/664/matches/\n"
     ]
    }
   ],
   "source": [
    "for team, url in first_three.items():\n",
    "    print(team,url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for team, url in first_three.items():\n",
    "\n",
    "    df_team_fixtures = fb_selenium_scrape(team = team, fb_url = url)\n",
    "\n",
    "    ## Add to master df\n",
    "    if 'df_fb_master' in locals():\n",
    "        df_fb_master = pd.concat([df_fb_master, df_team_fixtures], ignore_index=True)\n",
    "    else:\n",
    "        df_fb_master = df_team_fixtures.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Date</th>\n",
       "      <th>League</th>\n",
       "      <th>Home Team</th>\n",
       "      <th>Time</th>\n",
       "      <th>Away Team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arsenal</td>\n",
       "      <td>04/05/24</td>\n",
       "      <td>PRL</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>3 - 0</td>\n",
       "      <td>AFC Bournemouth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arsenal</td>\n",
       "      <td>12/05/24</td>\n",
       "      <td>PRL</td>\n",
       "      <td>Manchester United</td>\n",
       "      <td>0 - 1</td>\n",
       "      <td>Arsenal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arsenal</td>\n",
       "      <td>19/05/24</td>\n",
       "      <td>PRL</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>2 - 1</td>\n",
       "      <td>Everton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arsenal</td>\n",
       "      <td>24/07/24</td>\n",
       "      <td>CLF</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>P\\n                1 - 1\\n                P</td>\n",
       "      <td>AFC Bournemouth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arsenal</td>\n",
       "      <td>27/07/24</td>\n",
       "      <td>CLF</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>P\\n                2 - 1\\n                P</td>\n",
       "      <td>Manchester United</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Newcastle United</td>\n",
       "      <td>05/04/25</td>\n",
       "      <td>PRL</td>\n",
       "      <td>Leicester City</td>\n",
       "      <td>08 : 00</td>\n",
       "      <td>Newcastle United</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Newcastle United</td>\n",
       "      <td>12/04/25</td>\n",
       "      <td>PRL</td>\n",
       "      <td>Newcastle United</td>\n",
       "      <td>08 : 00</td>\n",
       "      <td>Manchester United</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Newcastle United</td>\n",
       "      <td>19/04/25</td>\n",
       "      <td>PRL</td>\n",
       "      <td>Aston Villa</td>\n",
       "      <td>08 : 00</td>\n",
       "      <td>Newcastle United</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Newcastle United</td>\n",
       "      <td>26/04/25</td>\n",
       "      <td>PRL</td>\n",
       "      <td>Newcastle United</td>\n",
       "      <td>08 : 00</td>\n",
       "      <td>Ipswich Town</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Newcastle United</td>\n",
       "      <td>03/05/25</td>\n",
       "      <td>PRL</td>\n",
       "      <td>Brighton &amp; Hove Albion</td>\n",
       "      <td>08 : 00</td>\n",
       "      <td>Newcastle United</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Team      Date League               Home Team  \\\n",
       "0             Arsenal  04/05/24    PRL                 Arsenal   \n",
       "1             Arsenal  12/05/24    PRL       Manchester United   \n",
       "2             Arsenal  19/05/24    PRL                 Arsenal   \n",
       "3             Arsenal  24/07/24    CLF                 Arsenal   \n",
       "4             Arsenal  27/07/24    CLF                 Arsenal   \n",
       "..                ...       ...    ...                     ...   \n",
       "145  Newcastle United  05/04/25    PRL          Leicester City   \n",
       "146  Newcastle United  12/04/25    PRL        Newcastle United   \n",
       "147  Newcastle United  19/04/25    PRL             Aston Villa   \n",
       "148  Newcastle United  26/04/25    PRL        Newcastle United   \n",
       "149  Newcastle United  03/05/25    PRL  Brighton & Hove Albion   \n",
       "\n",
       "                                            Time          Away Team  \n",
       "0                                          3 - 0    AFC Bournemouth  \n",
       "1                                          0 - 1            Arsenal  \n",
       "2                                          2 - 1            Everton  \n",
       "3    P\\n                1 - 1\\n                P    AFC Bournemouth  \n",
       "4    P\\n                2 - 1\\n                P  Manchester United  \n",
       "..                                           ...                ...  \n",
       "145                                      08 : 00   Newcastle United  \n",
       "146                                      08 : 00  Manchester United  \n",
       "147                                      08 : 00   Newcastle United  \n",
       "148                                      08 : 00       Ipswich Town  \n",
       "149                                      08 : 00   Newcastle United  \n",
       "\n",
       "[150 rows x 6 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fb_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Team\n",
       "Arsenal             50\n",
       "Manchester City     50\n",
       "Newcastle United    50\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fb_master.Team.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_abbr_data = pd.read_csv(r\"C:\\Users\\Owner\\Documents\\Data Projects\\GitHub\\Apps\\project_w\\data\\nba_team_abbr.csv\")\n",
    "today = datetime.now().date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init helper fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to apply the condition\n",
    "def get_game_time_status(date):\n",
    "    if date.date() >= today:\n",
    "        return 'Upcoming'\n",
    "    else:\n",
    "        return 'Past'\n",
    "    \n",
    "# Define a function to apply the condition\n",
    "def get_season(row_number):\n",
    "    if row_number >= 82:\n",
    "        return 'playoffs'\n",
    "    else:\n",
    "        return 'regular season'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build scraper fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the schedule from nba ref\n",
    "def retrieve_schedule(team_abbr):\n",
    "\n",
    "    # URL of the website\n",
    "    url = f\"https://www.basketball-reference.com/teams/{team_abbr}/2025_games.html\"\n",
    "\n",
    "    headers = {\n",
    "        \"User-Agent\": \"YourAppName/1.0 (https://yourwebsite.com; contact@yourwebsite.com)\"\n",
    "    }\n",
    "\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        time.sleep(4) # if successful, wait n secs before reading in the html\n",
    "        dfs_list = pd.read_html(url)\n",
    "\n",
    "        # Prep data\n",
    "        drop_cols = ['Unnamed: 3','Unnamed: 4']\n",
    "        col_mapping = {\n",
    "            'Unnamed: 5': 'Home/Away',\n",
    "            'Unnamed: 7': 'Result',\n",
    "            'Unnamed: 8': 'OT'\n",
    "        }\n",
    "\n",
    "        # Organize\n",
    "        df = pd.concat(dfs_list, ignore_index=True).drop(columns=drop_cols).rename(columns=col_mapping)\n",
    "        df['Home/Away'] = df['Home/Away'].fillna(\"vs.\")\n",
    "        df = df[df['Date'] != 'Date'].reset_index(drop=True)\n",
    "        df['computer_date'] = pd.to_datetime(df['Date'], format='%a, %b %d, %Y')\n",
    "        df['user_team'] = nba_abbr_data['team'][nba_abbr_data['abbr'] == team_abbr].iloc[0]\n",
    "        \n",
    "        # Create new cols from fns\n",
    "        df['GameTimeStatus'] = df['computer_date'].apply(lambda x: get_game_time_status(x))\n",
    "        df['game_type'] = df.index.to_series().apply(lambda x: get_season(x))\n",
    "        df['game_type'] = np.where(df['Notes'] == 'In-Season Tournament', 'In-Season Tournament', df['game_type']) # Apply conditional update to game_type column\n",
    "\n",
    "        return df\n",
    "    \n",
    "    else:\n",
    "        print(f\"Error retrieving data for {team_abbr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_html(\"https://www.basketball-reference.com/teams/ATL/2025_games.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through each nba team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nba_team in nba_abbr_data['abbr']:\n",
    "    \n",
    "    # Scrape\n",
    "    nba_team_sch = retrieve_schedule(nba_team)\n",
    "\n",
    "    # Check for dataframe\n",
    "    if 'df_nba_master' in locals():\n",
    "        df_nba_master = pd.concat([df_nba_master, nba_team_sch], ignore_index=True)\n",
    "    else:\n",
    "        df_nba_master = nba_team_sch.copy()\n",
    "\n",
    "    # Pause for n seconds to address HTTPError: HTTP Error 429: Too Many Requests\n",
    "    time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_nba_master.user_team.value_counts(), len(df_nba_master.user_team.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pho_team_sch = retrieve_schedule('PHO')\n",
    "# df_nba_master = pd.concat([df_nba_master, pho_team_sch], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nba_master.to_csv('df_nba_master_2024_10_29.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NHL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhl_abbr_data = pd.read_csv(r\"C:\\Users\\Owner\\Documents\\Data Projects\\GitHub\\Apps\\project_w\\data\\nhl_team_abbr.csv\")\n",
    "today = datetime.now().date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init helper fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to apply the condition\n",
    "def get_game_time_status(date):\n",
    "    if date.date() >= today:\n",
    "        return 'Upcoming'\n",
    "    else:\n",
    "        return 'Past'\n",
    "    \n",
    "# Define a function to apply the condition\n",
    "def get_season(row_number):\n",
    "    if row_number >= 82:\n",
    "        return 'playoffs'\n",
    "    else:\n",
    "        return 'regular season'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build scraper fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the schedule from nba ref\n",
    "def retrieve_nhl_schedule(team_abbr):\n",
    "\n",
    "    # URL of the website\n",
    "    url = f\"https://www.hockey-reference.com/teams/{team_abbr}/2025_games.html\"\n",
    "\n",
    "    headers = {\n",
    "        \"User-Agent\": \"YourAppName/1.0 (https://yourwebsite.com; contact@yourwebsite.com)\"\n",
    "    }\n",
    "\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        time.sleep(4) # if successful, wait n secs before reading in the html\n",
    "        dfs_list = pd.read_html(url)\n",
    "\n",
    "        # Prep data\n",
    "        col_mapping = {\n",
    "            'Unnamed: 3': 'Home/Away',\n",
    "            'Unnamed: 7': 'Result',\n",
    "            'Unnamed: 8': 'OT'\n",
    "        }\n",
    "\n",
    "        # Organize\n",
    "        df = pd.concat(dfs_list, ignore_index=True).rename(columns=col_mapping)\n",
    "        df['Home/Away'] = df['Home/Away'].fillna(\"vs.\")\n",
    "        df = df[df['Date'] != 'Date'].reset_index(drop=True)\n",
    "        df['computer_date'] = pd.to_datetime(df['Date'])\n",
    "        df['Date'] = df['computer_date'].dt.strftime('%a, %b %d, %Y')\n",
    "        df['user_team'] = nhl_abbr_data['team'][nhl_abbr_data['abbr'] == team_abbr].iloc[0]\n",
    "        \n",
    "        # Create new cols from fns\n",
    "        df['GameTimeStatus'] = df['computer_date'].apply(lambda x: get_game_time_status(x))\n",
    "        df['game_type'] = df.index.to_series().apply(lambda x: get_season(x))\n",
    "\n",
    "        return df\n",
    "    \n",
    "    else:\n",
    "        print(f\"Error retrieving data for {team_abbr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through each nhl team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nhl_team in nhl_abbr_data['abbr']:\n",
    "    \n",
    "    # Scrape\n",
    "    nhl_team_sch = retrieve_nhl_schedule(nhl_team)\n",
    "\n",
    "    # Check for dataframe\n",
    "    if 'df_nhl_master' in locals():\n",
    "        df_nhl_master = pd.concat([df_nhl_master, nhl_team_sch], ignore_index=True)\n",
    "    else:\n",
    "        df_nhl_master = nhl_team_sch.copy()\n",
    "\n",
    "    # Pause for n seconds to address HTTPError: HTTP Error 429: Too Many Requests\n",
    "    time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_nhl_master.user_team.value_counts(), len(df_nhl_master.user_team.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# veg_team_sch = retrieve_nhl_schedule('VEG')\n",
    "# df_nhl_master = pd.concat([df_nhl_master, veg_team_sch], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nhl_master.to_csv('df_nhl_master_2024_10_30.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nhl_master[(df_nhl_master['user_team'] == 'Colorado Avalanche') & (df_nhl_master['GameTimeStatus'] == 'Upcoming')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NFL (reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import time\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfl_abbr_data = pd.read_csv(r\"C:\\Users\\Owner\\Documents\\Data Projects\\GitHub\\Apps\\project_w\\data\\nfl_team_abbr.csv\")\n",
    "today = datetime.now().date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build scraper fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the schedule from nba ref\n",
    "def retrieve_nfl_schedule(team_abbr):\n",
    "\n",
    "    # URL of the website\n",
    "    url = f\"https://www.pro-football-reference.com/teams/{team_abbr}/2024/gamelog/\"\n",
    "\n",
    "    headers = {\n",
    "        \"User-Agent\": \"YourAppName/1.0 (https://yourwebsite.com; contact@yourwebsite.com)\"\n",
    "    }\n",
    "\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        time.sleep(4) # if successful, wait n secs before reading in the html\n",
    "        dfs_list = pd.read_html(url)\n",
    "\n",
    "        # Concatenate all DataFrames in dfs_list\n",
    "        df = pd.concat(dfs_list, ignore_index=True)\n",
    "\n",
    "        # Flatten the multi-level columns, ignoring 'Unnamed' and removing '_level_'\n",
    "        df.columns = [\n",
    "            re.sub(r'\\d+\\s', '', ' '.join(col).strip().replace(\"Unnamed: \", \"\").replace(\"_level_\", \"\")).replace(\"0\", \"\").replace(\"1\", \"\").replace(\"6\",\"Home/Away\").replace(\"4\",\"Result\")\n",
    "            for col in df.columns\n",
    "        ]\n",
    "\n",
    "        df = df.drop(columns='3')\n",
    "\n",
    "        # Organize\n",
    "        df['Home/Away'] = df['Home/Away'].fillna(\"vs.\")\n",
    "        df['user_team'] = nfl_abbr_data['team'][nfl_abbr_data['abbr'] == team_abbr].iloc[0]\n",
    "        df['game_type'] = \"regular season\"\n",
    "\n",
    "        return df\n",
    "    \n",
    "    else:\n",
    "        print(f\"Error retrieving data for {team_abbr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through each nfl team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nfl_team in nfl_abbr_data['abbr']:\n",
    "    \n",
    "    # Scrape\n",
    "    nfl_team_sch = retrieve_nfl_schedule(nfl_team)\n",
    "\n",
    "    # Check for dataframe\n",
    "    if 'df_nfl_master' in locals():\n",
    "        df_nfl_master = pd.concat([df_nfl_master, nfl_team_sch], ignore_index=True)\n",
    "    else:\n",
    "        df_nfl_master = nfl_team_sch.copy()\n",
    "\n",
    "    # Pause for n seconds to address HTTPError: HTTP Error 429: Too Many Requests\n",
    "    time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_nfl_master.user_team.value_counts(), len(df_nfl_master.user_team.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nfl_master.to_csv('df_nfl_master_2024_10_31.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NFL (espn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import time\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfl_abbr_data = pd.read_csv(r\"C:\\Users\\Owner\\Documents\\Data Projects\\GitHub\\Apps\\project_w\\data\\nfl_espn_team_abbr.csv\")\n",
    "# today = datetime.now().date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build scraper fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the schedule from nba ref\n",
    "def retrieve_espn_nfl_schedule(team_abbr):\n",
    "\n",
    "    # URL of the website\n",
    "    url = f\"https://www.espn.com/nfl/team/schedule/_/name/{team_abbr}\"\n",
    "\n",
    "    headers = {\n",
    "        \"User-Agent\": \"YourAppName/1.0 (https://yourwebsite.com; contact@yourwebsite.com)\"\n",
    "    }\n",
    "\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        time.sleep(4) # if successful, wait n secs before reading in the html\n",
    "        df = pd.read_html(url)[0]\n",
    "\n",
    "        # Find the index of the row that starts with \"WK\", \"DATE\", etc.\n",
    "        start_row = df[(df[0] == \"WK\") & (df[1] == \"DATE\") & (df[2] == \"OPPONENT\") & (df[3] == \"TIME\")].index[0]\n",
    "\n",
    "        # Find the index of the row that starts with \"Preseason\"\n",
    "        end_row = df[df[0] == \"Preseason\"].index[0]\n",
    "\n",
    "        # Select rows between the start and end rows, and set the start_row as the header\n",
    "        df = df.iloc[(start_row-1) + 1:end_row].reset_index(drop=True)  # +1 to exclude the header row from the data\n",
    "        df.columns = df.iloc[0]  # Set the first row of the selection as column headers\n",
    "        df = df[1:]  # Drop the header row itself\n",
    "\n",
    "        # Filter out rows where any cell has \"BYE WEEK\"\n",
    "        df = df[~df.eq(\"BYE WEEK\").any(axis=1)]\n",
    "\n",
    "        # Drop the first column and the last two columns\n",
    "        df = df.iloc[:, :-2].reset_index(drop=True)\n",
    "\n",
    "        # Extract \"vs\" or \"@\" into a new column \"Home/Away\"\n",
    "        df['Home/Away'] = df['OPPONENT'].str.extract(r'(vs|@)')\n",
    "        df['Home/Away'] = df['Home/Away'].replace('vs', 'vs.')\n",
    "\n",
    "        # Remove \"vs\" or \"@\" from the \"OPPONENT\" column and strip whitespace\n",
    "        df['OPPONENT'] = df['OPPONENT'].str.replace(r'vs |@ ', '', regex=True).str.strip()\n",
    "\n",
    "        ## Organize\n",
    "        df['user_team'] = nfl_abbr_data['team'][nfl_abbr_data['abbr'] == team_abbr].iloc[0]\n",
    "        df['game_type'] = \"regular season\"\n",
    "        df = df.drop(columns=df.filter(regex=\"^tickets$\").columns)\n",
    "        df['TIME'] = df['TIME'].replace(\"TBD\", pd.NA)\n",
    "\n",
    "        # Replace \"TBD\" with NaN using loc\n",
    "        df.loc[df['DATE'].str.contains('TBD'), 'DATE'] = np.nan\n",
    "\n",
    "        return df\n",
    "    \n",
    "    else:\n",
    "        print(f\"Error retrieving data for {team_abbr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through each nfl team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nfl_team in nfl_abbr_data['abbr']:\n",
    "    \n",
    "    # Scrape\n",
    "    nfl_team_sch = retrieve_espn_nfl_schedule(nfl_team)\n",
    "\n",
    "    # Check for dataframe\n",
    "    if 'df_nfl_master' in locals():\n",
    "        df_nfl_master = pd.concat([df_nfl_master, nfl_team_sch], ignore_index=True)\n",
    "    else:\n",
    "        df_nfl_master = nfl_team_sch.copy()\n",
    "\n",
    "    # Pause for n seconds to address HTTPError: HTTP Error 429: Too Many Requests\n",
    "    time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Miami Dolphins           10\n",
      "Dallas Cowboys           10\n",
      "Kansas City Chiefs       10\n",
      "Philadelphia Eagles      10\n",
      "Detroit Lions            10\n",
      "Los Angeles Chargers     10\n",
      "Chicago Bears            10\n",
      "Los Angeles Rams         10\n",
      "Tennessee Titans         10\n",
      "Minnesota Vikings        10\n",
      "Seattle Seahawks          9\n",
      "San Francisco 49ers       9\n",
      "New England Patriots      9\n",
      "Pittsburgh Steelers       9\n",
      "Tampa Bay Buccaneers      9\n",
      "Las Vegas Raiders         9\n",
      "New York Giants           9\n",
      "New Orleans Saints        9\n",
      "Arizona Cardinals         9\n",
      "Atlanta Falcons           9\n",
      "Jacksonville Jaguars      9\n",
      "Indianapolis Colts        9\n",
      "Green Bay Packers         9\n",
      "Denver Broncos            9\n",
      "Cleveland Browns          9\n",
      "Cincinnati Bengals        9\n",
      "Carolina Panthers         9\n",
      "Buffalo Bills             9\n",
      "Baltimore Ravens          9\n",
      "Washington Commanders     9\n",
      "New York Jets             8\n",
      "Houston Texans            8\n",
      "Name: user_team, dtype: int64 32\n"
     ]
    }
   ],
   "source": [
    "print(df_nfl_master.user_team.value_counts(), len(df_nfl_master.user_team.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teams in `df_nfl_master.user_team` but not in `nfl_abbr_data.team`: set()\n",
      "Teams in `nfl_abbr_data.team` but not in `df_nfl_master.user_team`: set()\n"
     ]
    }
   ],
   "source": [
    "# Convert both arrays to sets\n",
    "user_team_set = set(df_nfl_master.user_team.unique())\n",
    "abbr_team_set = set(nfl_abbr_data.team.unique())\n",
    "\n",
    "# Find differences\n",
    "only_in_user_team = user_team_set - abbr_team_set\n",
    "only_in_abbr_team = abbr_team_set - user_team_set\n",
    "\n",
    "# Display results\n",
    "print(\"Teams in `df_nfl_master.user_team` but not in `nfl_abbr_data.team`:\", only_in_user_team)\n",
    "print(\"Teams in `nfl_abbr_data.team` but not in `df_nfl_master.user_team`:\", only_in_abbr_team)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nfl_master['Home/Away'] = df_nfl_master['Home/Away'].replace('vs', 'vs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nfl_master.to_csv('df_nfl_master_2024_11_01.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WK</th>\n",
       "      <th>DATE</th>\n",
       "      <th>OPPONENT</th>\n",
       "      <th>TIME</th>\n",
       "      <th>TV</th>\n",
       "      <th>Home/Away</th>\n",
       "      <th>user_team</th>\n",
       "      <th>game_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>Sun, Nov 3</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>4:05 PM</td>\n",
       "      <td>CBS</td>\n",
       "      <td>vs.</td>\n",
       "      <td>Arizona Cardinals</td>\n",
       "      <td>regular season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Sun, Nov 10</td>\n",
       "      <td>New York</td>\n",
       "      <td>4:25 PM</td>\n",
       "      <td>CBS</td>\n",
       "      <td>vs.</td>\n",
       "      <td>Arizona Cardinals</td>\n",
       "      <td>regular season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>Sun, Nov 24</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>4:25 PM</td>\n",
       "      <td>FOX</td>\n",
       "      <td>@</td>\n",
       "      <td>Arizona Cardinals</td>\n",
       "      <td>regular season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>Sun, Dec 1</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>1:00 PM</td>\n",
       "      <td>FOX</td>\n",
       "      <td>@</td>\n",
       "      <td>Arizona Cardinals</td>\n",
       "      <td>regular season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>Sun, Dec 8</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>4:05 PM</td>\n",
       "      <td>CBS</td>\n",
       "      <td>vs.</td>\n",
       "      <td>Arizona Cardinals</td>\n",
       "      <td>regular season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>13</td>\n",
       "      <td>Sun, Dec 1</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>1:00 PM</td>\n",
       "      <td>CBS</td>\n",
       "      <td>vs.</td>\n",
       "      <td>Washington Commanders</td>\n",
       "      <td>regular season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>15</td>\n",
       "      <td>Sun, Dec 15</td>\n",
       "      <td>New Orleans</td>\n",
       "      <td>1:00 PM</td>\n",
       "      <td>FOX</td>\n",
       "      <td>@</td>\n",
       "      <td>Washington Commanders</td>\n",
       "      <td>regular season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>16</td>\n",
       "      <td>Sun, Dec 22</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>1:00 PM</td>\n",
       "      <td>FOX</td>\n",
       "      <td>vs.</td>\n",
       "      <td>Washington Commanders</td>\n",
       "      <td>regular season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vs.</td>\n",
       "      <td>Washington Commanders</td>\n",
       "      <td>regular season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@</td>\n",
       "      <td>Washington Commanders</td>\n",
       "      <td>regular season</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>296 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0    WK         DATE      OPPONENT     TIME   TV Home/Away  \\\n",
       "0     9   Sun, Nov 3       Chicago  4:05 PM  CBS       vs.   \n",
       "1    10  Sun, Nov 10      New York  4:25 PM  CBS       vs.   \n",
       "2    12  Sun, Nov 24       Seattle  4:25 PM  FOX         @   \n",
       "3    13   Sun, Dec 1     Minnesota  1:00 PM  FOX         @   \n",
       "4    14   Sun, Dec 8       Seattle  4:05 PM  CBS       vs.   \n",
       "..   ..          ...           ...      ...  ...       ...   \n",
       "291  13   Sun, Dec 1     Tennessee  1:00 PM  CBS       vs.   \n",
       "292  15  Sun, Dec 15   New Orleans  1:00 PM  FOX         @   \n",
       "293  16  Sun, Dec 22  Philadelphia  1:00 PM  FOX       vs.   \n",
       "294  17          NaN       Atlanta     <NA>  NaN       vs.   \n",
       "295  18          NaN        Dallas     <NA>  NaN         @   \n",
       "\n",
       "0                user_team       game_type  \n",
       "0        Arizona Cardinals  regular season  \n",
       "1        Arizona Cardinals  regular season  \n",
       "2        Arizona Cardinals  regular season  \n",
       "3        Arizona Cardinals  regular season  \n",
       "4        Arizona Cardinals  regular season  \n",
       "..                     ...             ...  \n",
       "291  Washington Commanders  regular season  \n",
       "292  Washington Commanders  regular season  \n",
       "293  Washington Commanders  regular season  \n",
       "294  Washington Commanders  regular season  \n",
       "295  Washington Commanders  regular season  \n",
       "\n",
       "[296 rows x 8 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nfl_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
